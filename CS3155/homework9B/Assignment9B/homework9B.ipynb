{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-d9359f2ff259>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-d9359f2ff259>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    import $file.hw9Bstdlib\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import $file.hw9Bstdlib\n",
    "import $file.hw9Bparserlib\n",
    "import hw9Bstdlib._\n",
    "import hw9Bparserlib._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "543bf5aa1e1b36fb0e96a4ddcce5c116",
     "grade": false,
     "grade_id": "cell-e83a431d6a2ac8f0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Homework 9B - The Lettuce Parser\n",
    "\n",
    "We have an eval function from hw7 and a lexer from hw9. Once we create our parser we can hook everything together to have a functioning language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e4d3e5218df1ea545a2d217814085f54",
     "grade": false,
     "grade_id": "cell-b8e37288f5cdaa58",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## The Interpreter\n",
    "Below is the solution to the full eval function from hw7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-58016d1608a6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-58016d1608a6>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    //\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "//\n",
    "// Expressions\n",
    "//\n",
    "sealed trait Expr\n",
    "case class Num(x : Integer) extends Expr\n",
    "case class Bin(x : Bool) extends Expr\n",
    "case class Ident(x : String) extends Expr\n",
    "case class Plus(x : Expr, y : Expr) extends Expr\n",
    "case class Minus(x : Expr, y : Expr) extends Expr\n",
    "case class Mult(x : Expr, y : Expr) extends Expr\n",
    "case class Pow(x : Expr, y : Expr) extends Expr\n",
    "case class Neg(x : Expr) extends Expr\n",
    "case class Eq(x : Expr, y : Expr) extends Expr\n",
    "case class And(x : Expr, y : Expr) extends Expr\n",
    "case class Or(x : Expr, y : Expr) extends Expr\n",
    "case class IfThenElse(p : Expr, t : Expr, f : Expr) extends Expr\n",
    "case class Let(id : String, x : Expr, y : Expr) extends Expr\n",
    "case class FunDef(p: String, body: Expr) extends Expr\n",
    "case class FunCall(e_func: Expr, e_arg: Expr) extends Expr\n",
    "case class LetRec(f_name: String, arg_name: String, e_body: Expr, e_in: Expr) extends Expr\n",
    "\n",
    "//\n",
    "// Values\n",
    "//\n",
    "sealed trait Value\n",
    "case class NumVal(x : Integer) extends Value\n",
    "case class BinVal(x : Bool) extends Value\n",
    "case object Error extends Value\n",
    "case class Closure(p: String, body: Expr, env: Environment) extends Value\n",
    "\n",
    "//\n",
    "// Environment\n",
    "//\n",
    "sealed trait Environment\n",
    "case object EmptyEnv extends Environment \n",
    "case class Extend(k : String, v : Value, env : Environment) extends Environment\n",
    "case class ExtendRec(f: String, x: String, e: Expr, sigma: Environment ) extends Environment\n",
    "def lookupEnv(sigma: Environment, x: String): Maybe[Value] = sigma match {\n",
    "    case EmptyEnv => None\n",
    "    case Extend(y, v, pi) => string_eq(y,x) match {\n",
    "        case True => Just(v)\n",
    "        case False => lookupEnv(pi, x)\n",
    "    } \n",
    "    case ExtendRec(f, y, e, pi) => string_eq(x,f) match {\n",
    "        case True => Just(Closure(y, e, sigma))\n",
    "        case False => lookupEnv(pi, x)\n",
    "    } \n",
    "}\n",
    "\n",
    "//\n",
    "// Eval\n",
    "//\n",
    "def eval(env : Environment, expr : Expr) : Value = expr match {\n",
    "    case Num(n)    => NumVal(n)\n",
    "    case Bin(p)    => BinVal(p)\n",
    "    case Ident(id) => lookupEnv(env, id) match {\n",
    "        case Just(v) => v\n",
    "        case None    => Error\n",
    "    }\n",
    "    case Plus(e1, e2)  => eval_bin_arith(plus, env, e1, e2)\n",
    "    case Minus(e1, e2) => eval_bin_arith(minus, env, e1, e2)\n",
    "    case Mult(e1, e2)  => eval_bin_arith(mult, env, e1, e2)\n",
    "    case Pow(e1, e2)   => (eval(env, e1), eval(env,e2)) match {\n",
    "        case (NumVal(x), NumVal(Positive(n))) => NumVal(pow(x, n))\n",
    "        case _ => Error\n",
    "    }\n",
    "    case Neg(e) => eval(env, e) match {\n",
    "        case NumVal(x) => NumVal(negate(x))\n",
    "        case BinVal(p) => BinVal(not(p))\n",
    "        case Error     => Error\n",
    "    }\n",
    "    case Eq(e1, e2) => (eval(env, e1), eval(env, e2)) match {\n",
    "        case (NumVal(x), NumVal(y)) => BinVal(int_eq(x,y))\n",
    "        case (BinVal(p), BinVal(q)) => BinVal(bool_eq(p,q))\n",
    "        case _                      => Error\n",
    "    }\n",
    "    case And(e1, e2) => eval_bin_bool(and, env, e1, e2)\n",
    "    case Or(e1, e2)  => eval_bin_bool(or, env, e1, e2)\n",
    "    case IfThenElse(p, e_t, e_f) => eval(env, p) match{\n",
    "        case BinVal(True)  => eval(env, e_t)\n",
    "        case BinVal(False) => eval(env, e_f)\n",
    "        case _             => Error\n",
    "    }\n",
    "    case Let(id, df, body) => eval(env, df) match{\n",
    "        case Error => Error\n",
    "        case x     => {\n",
    "            val new_env = Extend(id, x, env)\n",
    "            eval(new_env , body)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    case FunDef(x, e_body) =>\n",
    "        Closure(x, e_body, env)\n",
    "    \n",
    "    case FunCall(e_f, e_arg) =>\n",
    "        eval(env, e_f) match {\n",
    "            case Closure(p, e_body, pi) => eval(env, e_arg) match {\n",
    "                case Error => Error\n",
    "                case v_a   => eval(Extend(p, v_a, pi), e_body)\n",
    "            }\n",
    "            case _ => Error\n",
    "        }\n",
    "    \n",
    "    case LetRec(x_name, x_param, e_body, e_in) =>\n",
    "        eval(ExtendRec(x_name, x_param, e_body, env), e_in)\n",
    "}\n",
    "\n",
    "def eval_bin_arith( op : (Integer, Integer) => Integer\n",
    "                  , env : Environment\n",
    "                  , e1 : Expr\n",
    "                  , e2 : Expr) : Value \n",
    "    = (eval(env, e1), eval(env, e2)) match{\n",
    "        case (NumVal(x), NumVal(y)) => NumVal(op(x,y))\n",
    "        case _ => Error\n",
    "    }\n",
    "\n",
    "def eval_bin_bool( op : (Bool, Bool) => Bool\n",
    "                 , env : Environment\n",
    "                 , e1 : Expr\n",
    "                 , e2 : Expr) : Value \n",
    "    = (eval(env, e1), eval(env, e2)) match{\n",
    "        case (BinVal(x), BinVal(y)) => BinVal(op(x,y))\n",
    "        case _ => Error\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "322da867ad061d89364ed0a83df534ff",
     "grade": false,
     "grade_id": "cell-2df3bce6feb7d016",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## The Lexer\n",
    "\n",
    "Below is the solution to the lexer from hw9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sealed trait KW\n",
    "case object KWFunction extends KW\n",
    "case object KWLet extends KW\n",
    "case object KWIn extends KW\n",
    "case object KWRec extends KW\n",
    "case object KWIf extends KW\n",
    "case object KWThen extends KW\n",
    "case object KWElse extends KW\n",
    "\n",
    "sealed trait Lit\n",
    "case class NumLiteral(x : Nat) extends Lit\n",
    "case class BoolLiteral(x : Bool) extends Lit\n",
    "\n",
    "sealed trait Lex \n",
    "case class Identifier(s : List[Char]) extends Lex\n",
    "case class Keyword(k : KW) extends Lex\n",
    "case class Operator(s : List[Char]) extends Lex\n",
    "case class Literal(l : Lit) extends Lex\n",
    "case class Comment(s : List[Char]) extends Lex \n",
    "case object OpenParen extends Lex\n",
    "case object CloseParen extends Lex\n",
    "\n",
    "def const[S,D,E](p : Parser[S,D], d : E) : Parser[S, E] = bind(p, (x : D) => success(d))\n",
    "\n",
    "def pLet : Parser[Char, Lex] = const(string(\"let\"), Keyword(KWLet))\n",
    "def pFunc : Parser[Char, Lex] = const(string(\"function\"), Keyword(KWFunction))\n",
    "def pRec : Parser[Char, Lex] = const(string(\"rec\"), Keyword(KWRec))\n",
    "def pIn : Parser[Char, Lex] = const(string(\"in\"), Keyword(KWIn))\n",
    "def pIf : Parser[Char, Lex] = const(string(\"if\"), Keyword(KWIf))\n",
    "def pThen : Parser[Char, Lex] = const(string(\"then\"), Keyword(KWThen))\n",
    "def pElse : Parser[Char, Lex] = const(string(\"else\"), Keyword(KWElse))\n",
    "def keywords : Parser[Char, Lex] = option(pLet, \n",
    "                                   option(pFunc, \n",
    "                                   option(pRec, \n",
    "                                   option(pIn,\n",
    "                                   option(pIf, \n",
    "                                   option(pThen, pElse))))))\n",
    "\n",
    "def pTrue : Parser[Char, Lex] = const(string(\"true\"), Literal(BoolLiteral(True)))\n",
    "def pFalse : Parser[Char, Lex] = const(string(\"false\"), Literal(BoolLiteral(False)))\n",
    "def pNumber : Parser[Char, Lex] = bind(number, \n",
    "                                        (n : Nat) => success(Literal(NumLiteral(n))))\n",
    "def literals : Parser[Char, Lex] = option(pTrue, \n",
    "                                   option(pFalse, pNumber))\n",
    "\n",
    "def isAlpha(c : Char) : Bool = if(c >= 'A' && c <= 'Z' || c >= 'a' && c <= 'z') True else False\n",
    "def alphanum : Parser[Char, Char] = option(digit, satisfies(isAlpha))\n",
    "def identifier : Parser[Char, Lex] = bind(satisfies(isAlpha), \n",
    "                                          (x : Char) => bind(many(alphanum),\n",
    "                                          (xs : List[Char]) => success(Identifier(Cons(x,xs)))))\n",
    "\n",
    "def isOperator(x : Char) : Bool = x match {\n",
    "    case '+' => True\n",
    "    case '-' => True\n",
    "    case '*' => True\n",
    "    case '^' => True\n",
    "    case '=' => True\n",
    "    case '&' => True\n",
    "    case '|' => True\n",
    "    case _   => False\n",
    "}\n",
    "def operators : Parser[Char, Lex] = option(\n",
    "                    bind(string(\"==\"),          (str : List[Char]) => success(Operator(str))),\n",
    "                    bind(satisfies(isOperator), (c : Char) => success(Operator(singleton(c)))))\n",
    "\n",
    "def parens : Parser[Char, Lex] = option(\n",
    "                                    const(char('('), OpenParen) ,\n",
    "                                    const(char(')'), CloseParen))\n",
    "\n",
    "def lexOne : Parser[Char, Lex] = option(keywords, \n",
    "                                 option(operators, \n",
    "                                 option(parens,\n",
    "                                 option(literals,\n",
    "                                        identifier))))\n",
    "\n",
    "def lexWhitespace : Parser[Char, List[Lex]] = const(whitespace, Empty)\n",
    "\n",
    "def lexParens : Parser[Char, List[Lex]] = bind(parens, (x : Lex) => \n",
    "                                          bind(maybeWhitespace,\n",
    "                                               (ws : List[Char]) => success(singleton(x))))\n",
    "\n",
    "\n",
    "def lexToken : Parser[Char, List[Lex]] = bind(lexOne, \n",
    "                                             (l : Lex) => bind(option(lexParens, lexWhitespace),\n",
    "                                             (sep : List[Lex]) => success(Cons(l, sep))))\n",
    "\n",
    "def concat[A](xs : List[List[A]]) : List[A] = xs match {\n",
    "    case Empty => Empty\n",
    "    case Cons(xs, xxs) => append(xs, concat(xxs))\n",
    "}\n",
    "\n",
    "\n",
    "def lexer : Parser[Char, List[Lex]] = bind(many(lexToken), \n",
    "                   (ls : List[List[Lex]]) =>\n",
    "                   success(concat(ls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "80d1120fe5cac0971d206c416f505832",
     "grade": false,
     "grade_id": "cell-5a7ffdd12ab6f4aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Formal Grammars\n",
    "\n",
    "While we have been using BNF grammars to represent constructed values, their original purpose was to define languages.\n",
    "The below grammar defines the language with only the strings `\"ab\"` and `bc`\n",
    "$$\n",
    "\\begin{align}\n",
    "    S ::=&\\ \\texttt{a}\\ \\texttt{b} \\\\\n",
    "     \\mid&\\ \\texttt{b}\\ \\texttt{c}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Each production (each \"thing\" seperated by $\\mid$ operators to the right of the $::=$) is read verbatim other than the non terminals. Non-terminals are the names defined to the left of the $::=$. In this case the only non-terminal is $S$. Non-terminals are expanded recursively.\n",
    "\n",
    "The equivalent parser would be:\n",
    "```scala\n",
    "val S = choose(\n",
    "    bind(char('a'), (_: Char) => char('b')),\n",
    "    bind(char('b'), (_: Char) => char('c'))\n",
    ")\n",
    "```\n",
    "\n",
    "A recursive example could be something like:\n",
    "$$\n",
    "\\begin{align}\n",
    "    S ::=&\\ \\texttt{a}\\ S\\ \\texttt{b} \\\\\n",
    "     \\mid&\\ \\texttt{z}\\ \\texttt{X} \\\\\n",
    "     \\mid&\\ \\epsilon\n",
    "\\end{align}\n",
    "$$\n",
    "This definition also includes the special symbol $\\epsilon$ (epsilon). This means the empty string.\n",
    "\n",
    "Examples of strings in this language are:\n",
    "```\n",
    "\"ab\"\n",
    "\"aaabbb\"\n",
    "\"aaazXbbb\"\n",
    "\"zX\"\n",
    "\"\"\n",
    "```\n",
    "\n",
    "And the equivalent scala parser would be:\n",
    "```scala\n",
    "val S = choose(\n",
    "    bind(char('a'), (_: Char) => bind(S, (_: Char) => char('b'))), // a S b\n",
    "    choose(\n",
    "        bind(char('z'), (_: Char) => char('X')),                   // z X\n",
    "        success(???)                                               // epsilon\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "### A basic lettuce grammar\n",
    "To write the parser for Lettuce, we first have to give a formal specification of the language.\n",
    "This is given below:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Lettuce ::=&\\ E\\\\\n",
    "    \\\\\n",
    "    Z ::=&\\ ... &\\text{Imaginary definition for numbers}\\\\\n",
    "    \\\\\n",
    "    Ident ::=&\\ ... &\\text{Imaginary definition for variables}\\\\\n",
    "     \\\\\n",
    "    B ::=&\\ \\texttt{true}\\\\\n",
    "      \\mid&\\ \\texttt{false}\\\\\n",
    "     \\\\\n",
    "    E ::=&\\ \\color{green}{Z} &\\text{Numbers}\\\\\n",
    "     \\mid&\\ \\color{green}{B} &\\text{Booleans}\\\\\n",
    "     \\mid&\\ \\color{green}{Ident} &\\text{Variable names}\\\\\n",
    "     \\mid&\\ \\color{green}{E \\texttt{ + } E}  &\\text{Addition}\\\\\n",
    "     \\mid&\\ \\color{green}{E \\texttt{ * } E}  &\\text{Multiplication}\\\\\n",
    "     \\mid&\\ \\color{green}{\\texttt{-} E}  &\\text{Numeric Negation}\\\\\n",
    "     \\mid&\\ \\color{green}{\\texttt{( } E \\texttt{ )}}  &\\text{Parentheses}\\\\\n",
    "     \\mid&\\ \\color{green}{E \\texttt{ ( } E \\texttt{ )}}  &\\text{Function Calls}\\\\\n",
    "     \\mid&\\ \\color{green}{\\texttt{if } E \\texttt{ then } E \\texttt{ else } E}  &\\text{If-Else}\\\\\n",
    "     \\mid&\\ \\color{green}{\\texttt{function ( } Ident \\texttt{ ) } E}  &\\text{Function Definition}\\\\\n",
    "     \\mid&\\ \\color{green}{\\texttt{let } Ident \\texttt{ = } E \\texttt{ in } E}  &\\text{Let bindings}\\\\\n",
    "     \\mid&\\ E \\texttt{ - } E  &\\text{Subtraction}\\\\\n",
    "     \\mid&\\ E \\texttt{ ^ } E  &\\text{Exponentiation}\\\\\n",
    "     \\mid&\\ E \\texttt{ && } E  &\\text{And}\\\\\n",
    "     \\mid&\\ E \\mid \\mid E  &\\text{Or}\\\\\n",
    "     \\mid&\\ E \\texttt{ == } E &\\text{Equality} \\\\\n",
    "     \\mid&\\ \\texttt{!} E  &\\text{Boolean Negation}\\\\\n",
    "     \\mid&\\ \\texttt{let rec } Ident \\texttt{ = } \\texttt{function ( } Ident \\texttt{ ) } E \\texttt{ in } E  &\\text{Recursive let bindings}\\\\\n",
    "      \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can imagine that we have a definition for integers ($Z$) and variable names ($Ident$) because they are overly complicated to write out correctly.\n",
    "\n",
    "The words to the right side are just an english explanation of each rule, they are not part of the actual grammar. You can see above that we have defined Lettuce as an expression represented by the $E$ *non-terminal*. Just like how we've used BNF before, anything to the left of a $::=$ definition is a non-terminal, which means it can expand to any of the *productions* on the righthand side, each seperated with a pipe operator.\n",
    "\n",
    "**Note**: Because this would be a huge parser if we wrote all of it (and many of the rules are very similar to parse), we will instead focus on only the $\\color{green}{\\textbf{green}}$ subset.\n",
    "\n",
    "### Using the grammar\n",
    "\n",
    "A valid lettuce progrram is defined as one where we can write it using only the above productions, and which has no more non-terminals in it.\n",
    "\n",
    "For example, the following program: `let x = 5 in x + x` can be created by applying the rules in the following order (we always start with the $Lettuce$ non terminal when writing a lettuce program):\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    & Lettuce \\\\\n",
    "    & E \\\\\n",
    "    & \\texttt{let } Ident \\texttt{ = } E \\texttt{ in } E \\\\\n",
    "    & \\texttt{let x = } E \\texttt{ in } E \\\\\n",
    "    & \\texttt{let x = } Z \\texttt{ in } E \\\\\n",
    "    & \\texttt{let x = 5 in } E \\\\\n",
    "    & \\texttt{let x = 5 in } E \\texttt{ + } E \\\\\n",
    "    & \\texttt{let x = 5 in } Ident \\texttt{ + } E \\\\\n",
    "    & \\texttt{let x = 5 in x + } E \\\\\n",
    "    & \\texttt{let x = 5 in x + } Ident \\\\\n",
    "    & \\texttt{let x = 5 in x + x} \\\\\n",
    "    \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Problems with this naive approach\n",
    "\n",
    "There are some problems with the above definition:\n",
    "1. It is *left recursive*, which means that there is at least one production that has the non-terminal as the versy first thing in the production with no terminals (anything that isn't expanded) before it. An example of such a production is the addition rule, which has $E$ as the very first element. The problem with this is that no characters are consumed before we recurse, so the parsing could continue to loop indefinitely until we get a stack overflow.\n",
    "2. It doesn't enforce *operator associativity*. Meaning, `1 + 2 + 3` could parse as either `(1 + 2) + 3`, or `1 + (2 + 3)` In this case, the problem is that the same program could have different results for different runs, which would be awful for the user of our language to debug.\n",
    "3. It doesn't enforce *operator precedance*, meaning `1 + 2 * 3` could parse as `(1 + 2) * 3`, instead of the desired `1 + (2 * 3)`\n",
    "\n",
    "To solve all problems at once, we redefine the grammar to get rid of left recursion, while structuring it in a way that operators have the desired associativity and precedance. We do this by introducing levels of expressions, that let the nested expressions change to a stronger precedence, but not a weaker one. Here is an example for just plus and multiplication:\n",
    "\n",
    "**Note**: $\\epsilon$ below is a special non-terminal that signifies the empty string.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    E0 ::=&\\ E1\\ Pluses \\\\\n",
    "    Pluses ::=&\\ \\texttt{+ } E1\\ Pluses \\\\\n",
    "          \\mid&\\ \\epsilon \\\\\n",
    "    \\\\\n",
    "    E1 ::=&\\ E2\\ Mults \\\\\n",
    "    Mults ::=&\\ \\texttt{* } E2\\ Mults \\\\\n",
    "         \\mid&\\ \\epsilon \\\\\n",
    "    \\\\\n",
    "    E2 ::=&\\ Z \\\\\n",
    "      \\mid&\\ \\texttt{( } E0 \\texttt{ )} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "1. You can see that there is no more left recursion in the grammar.\n",
    "2. By using $Pluses$ to parse addition left to right, we can control the associativity of the operator.\n",
    "3. By defining addition to only have $E1$ as a nested expression, we can control the precedence of the plus operator.\n",
    "\n",
    "We can still multiply the result of additions of course, but now we must do it by parenthesizing the addition, just like in math.\n",
    "\n",
    "###  Fixed grammar\n",
    "\n",
    "**Note**: $E^0, E^1, ...$ are the non-terminals that represent different precedence levels. The superscript isn't a special notation, it's just easier to read than $E0, E1, ...$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    E ::=&\\ E^0 \\\\\n",
    "    \\\\\n",
    "    E^0 ::=&\\ E^1 Pluses \\\\\n",
    "    Pluses ::=&\\ \\texttt{+ } E^1 Pluses \\\\\n",
    "          \\mid&\\ \\epsilon \\\\\n",
    "    \\\\\n",
    "    E^1 ::=&\\ E^2 Mults \\\\\n",
    "    Mults ::=&\\ \\texttt{* } E^2 Mults \\\\\n",
    "         \\mid&\\ \\epsilon \\\\\n",
    "    \\\\\n",
    "    E^2 ::=&\\ - E^2 \\\\\n",
    "       \\mid&\\ E^3 \\\\\n",
    "    \\\\\n",
    "    E^3 ::=&\\ E^4 Calls \\\\\n",
    "    Calls ::=&\\ \\texttt{( } E^4 \\texttt{ ) } Calls \\\\\n",
    "         \\mid&\\ \\epsilon \\\\\n",
    "    \\\\\n",
    "    E^4 ::=&\\ Z \\\\\n",
    "       \\mid&\\ B \\\\\n",
    "       \\mid&\\ Ident \\\\\n",
    "       \\mid&\\ \\texttt{let } Ident \\texttt{ = } E \\texttt{ in } E \\\\\n",
    "       \\mid&\\ \\texttt{function ( } Ident \\texttt{ ) } E \\\\\n",
    "       \\mid&\\ \\texttt{if } E \\texttt{ then } E \\texttt{ else } E \\\\\n",
    "       \\mid&\\ \\texttt{( } E \\texttt{ )} \\\\\n",
    "    \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### New library funcs\n",
    "\n",
    "We have defined a new helper in the next cell that you may find useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(l: List[Char]): String =\n",
    "    fold((_: Char) + (_: String), \"\", reverse(l))\n",
    "\n",
    "//\n",
    "// Ignore Below\n",
    "//\n",
    "\n",
    "// Translates between built in booleans and our Bool type\n",
    "def to_bool(b: Boolean): Bool = if (b) True else False\n",
    "\n",
    "// Gets the data portion out of parsed pair\n",
    "def get_data[S, D](parse: (D, List[S])): D = parse._1\n",
    "\n",
    "def parse_finished[A, B](parse: (A, List[B])): Bool = to_bool(parse._2 == Empty)\n",
    "\n",
    "def lexEq(l1: Lex, l2: Lex): Bool = if (l1 == l2) True else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f3d6ab147bfa31cbd101e8a07411ea8e",
     "grade": false,
     "grade_id": "cell-f12461fbd4c68fb9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Running the parser\n",
    "The new parser you're going to write will need to be run on the result of the lexer, so we have `runExprParser` defined below to make this easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExprParser(p : Parser[Lex, Expr], s : String) : Maybe[Expr] = runParser(lexer, s) match {\n",
    "    case Just(l) => map(get_data[Lex, Expr], filter(parse_finished, p(l))) match {\n",
    "        case Cons(expr, _) => Just(expr)\n",
    "        case _ => None\n",
    "    } \n",
    "    case None => None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e746e3c4e5de9d131a852be009fca201",
     "grade": false,
     "grade_id": "cell-4383008cf410980c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### New Parser combinators\n",
    "Just as we had some primitives to build up parsers for `Char`s, we built new ones for dealing with lex tokens as our symbols. With characters, we only had the `char` function to generate parsers, but `Lex` values have more structure, so we now have the following: \n",
    "\n",
    "* `def parseOperator(op_str: String)` - This parser generator takes a string and produces a parser that expects that operator. Example:\n",
    "    ```\n",
    "    parseOperator(\"==\") // Accepts only `Operator(\"==\")`\n",
    "    ```\n",
    "\n",
    "* `def parseNumLex` and `def parseBoolLex` - Take no argumenst, parse a `Literal(NumLiteral(...))` and `Literal(BoolLiteral(...))` lexeme into a `Nat` and a `Bool` respectively.\n",
    "* `def parseKeyword(kw : KW)` - Parses the given keyword. Example:\n",
    "    ```\n",
    "    parseKeyword(KWLet) // Accepts only `KWLet` from our list of lexemes\n",
    "    ```\n",
    "* `def parseOpenParen` and `def parseCloseParen` - Parses the given keyword\n",
    "    ```\n",
    "    parseKeyword(KWLet) // Accepts only `KWLet` from our list of lexemes\n",
    "    ```\n",
    "* `def parseIdentifierLex` - Parses the `Identifier` lexeme into the string representing the variable name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseNumLex : Parser[Lex, Nat] = (l : List[Lex]) => l match {\n",
    "    case Cons(Literal(NumLiteral(n)), xs) => singleton((n, xs))\n",
    "    case _ => Empty\n",
    "}\n",
    "\n",
    "def parseBoolLex : Parser[Lex, Bool] = (l : List[Lex]) => l match {\n",
    "    case Cons(Literal(BoolLiteral(n)), xs) => singleton((n, xs))\n",
    "    case _ => Empty\n",
    "}\n",
    "\n",
    "def parseOperator(op_str: String) : Parser[Lex, Lex] = satisfies(lexEq(_, Operator(string_to_list(op_str))))\n",
    "\n",
    "def parseKeyword(kw : KW) : Parser[Lex, KW] = (ls : List[Lex]) => ls match {\n",
    "    case Cons(Keyword(`kw`), xs) => singleton(kw, xs)\n",
    "    case _ => Empty\n",
    "}\n",
    "\n",
    "def parseIdentifierLex : Parser[Lex, List[Char]] = (ls : List[Lex]) => ls match {\n",
    "    case Cons(Identifier(x), xs) => singleton(x, xs)\n",
    "    case _                       => Empty\n",
    "}\n",
    "\n",
    "\n",
    "def parseOpenParen : Parser[Lex, Lex] = (ls : List[Lex]) => ls match {\n",
    "    case Cons(OpenParen, xs) => singleton(OpenParen, xs)\n",
    "    case _                   => Empty\n",
    "}\n",
    "\n",
    "def parseCloseParen : Parser[Lex, Lex] = (ls : List[Lex]) => ls match {\n",
    "    case Cons(CloseParen, xs) => singleton(CloseParen, xs)\n",
    "    case _                    => Empty\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0d94513395da06841e35dd757999ac0b",
     "grade": false,
     "grade_id": "cell-032723b8966aba43",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem: Parser (40pts)\n",
    "Define the parser given by the fixed grammar above by filling in the code bellow. Because the entire parser is mutually recursive, all code must unfortunately be compiled in the same cell. Which can get annoying since there are many `???`s. To get around this, you'll want to coment out or stub out sections to test subsets as you implement them. For example, until you are ready to implement multiplication, pass over `parseE1` by setting it to the following (though you should leave a `// TODO` comment so you don't forget to fill it in later).\n",
    "\n",
    "```scala\n",
    "def parseE1: Parser[Lex, Expr] =\n",
    "    parseE2 // Do nothing, move on to E2 parser\n",
    "```\n",
    "\n",
    "The suggested order of attack is following the tests:\n",
    "```\n",
    "parseBoolLit\n",
    "parseIdentifier\n",
    "parseE1 && parseMults\n",
    "parseE2\n",
    "parseE3 && parseCalls\n",
    "parseLet\n",
    "parseIf\n",
    "parseParenthesized\n",
    "parseFunction\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-6ec9d6e13633>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-6ec9d6e13633>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    //\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "//\n",
    "// E\n",
    "//\n",
    "def parseE: Parser[Lex, Expr] =\n",
    "    parseE0(_) // ignore the `(_)`\n",
    "\n",
    "//\n",
    "// E^0\n",
    "//\n",
    "def parseE0: Parser[Lex, Expr] =\n",
    "    bind(parseE1, parsePluses)\n",
    "\n",
    "def parsePluses(e1: Expr): Parser[Lex, Expr] =\n",
    "    option(bind(parseOperator(\"+\"), (_: Lex) =>\n",
    "           bind(parseE1,            (e2: Expr) =>\n",
    "                parsePluses(Plus(e1, e2)))),\n",
    "           success(e1))\n",
    "\n",
    "//\n",
    "// E^1\n",
    "//\n",
    "def parseE1: Parser[Lex, Expr] =\n",
    "    // YOUR CODE HERE\n",
    "    ???\n",
    "\n",
    "def parseMults(e1: Expr): Parser[Lex, Expr] =\n",
    "    // YOUR CODE HERE\n",
    "    ???\n",
    "\n",
    "//\n",
    "// E^2\n",
    "//\n",
    "def parseE2: Parser[Lex, Expr] =\n",
    "    // YOUR CODE HERE\n",
    "    ???\n",
    "\n",
    "//\n",
    "// E^3\n",
    "//\n",
    "def parseE3: Parser[Lex, Expr] =\n",
    "    bind(parseE4, parseCalls)\n",
    "def parseCalls(e1: Expr): Parser[Lex, Expr] =\n",
    "    // YOUR CODE HERE\n",
    "    ???\n",
    "\n",
    "//\n",
    "// E^4\n",
    "//\n",
    "def parseE4: Parser[Lex, Expr] =\n",
    "    choose(parseBoolLit,\n",
    "    choose(parseNumLit,\n",
    "    choose(parseIdentifier,\n",
    "    choose(parseLet,\n",
    "    choose(parseFunction,\n",
    "    choose(parseIf,\n",
    "           parseParenthesized))))))\n",
    "\n",
    "\n",
    "def parseNumLit: Parser[Lex, Expr] =\n",
    "    bind(parseNumLex, (n: Nat) =>\n",
    "         success(Num(Positive(n))))\n",
    "\n",
    "def parseBoolLit: Parser[Lex, Expr] =\n",
    "    // YOUR CODE HERE\n",
    "    ???\n",
    "\n",
    "def parseIdentifier: Parser[Lex, Expr] =\n",
    "    // YOUR CODE HERE\n",
    "    ???\n",
    "\n",
    "def parseLet: Parser[Lex, Expr] =\n",
    "    bind(parseKeyword(KWLet), (_: KW) =>\n",
    "    bind(parseIdentifierLex,  (x : List[Char]) =>\n",
    "    bind(parseOperator(\"=\"),  (_: Lex) =>\n",
    "    bind(parseE,              (e1 : Expr) =>\n",
    "    bind(parseKeyword(KWIn),  (_ : KW) =>\n",
    "    bind(parseE,              (e2 : Expr) =>\n",
    "         success(Let(list_to_string(x), e1, e2))))))))\n",
    "\n",
    "def parseIf: Parser[Lex, Expr] =\n",
    "    // YOUR CODE HERE\n",
    "    ???\n",
    "\n",
    "def parseParenthesized: Parser[Lex, Expr] =\n",
    "    // YOUR CODE HERE\n",
    "    ???\n",
    "\n",
    "def parseFunction: Parser[Lex, Expr] =\n",
    "    // YOUR CODE HERE\n",
    "    ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret(program: String): Maybe[Value] = runExprParser(parseE, program) match {\n",
    "    case Just(e) => Just(eval(EmptyEnv, e))\n",
    "    case None => None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Booleans\n",
    "assert(runExprParser(parseE, \"true \") == Just(Bin(True)))\n",
    "assert(runExprParser(parseE, \"false \") == Just(Bin(False)))\n",
    "passed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Identifiers\n",
    "assert(runExprParser(parseE, \"x \") == Just(Ident(\"x\")))\n",
    "assert(runExprParser(parseE, \"abcd \") == Just(Ident(\"abcd\")))\n",
    "passed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Multiplication\n",
    "val x = Ident(\"x\")\n",
    "assert(runExprParser(parseE, \"x * x \") == Just(Mult(x, x)))\n",
    "assert(runExprParser(parseE, \"x * x * y \") == Just(Mult(Mult(x, x), Ident(\"y\"))))\n",
    "assert(runExprParser(parseE, \"x + x * y \") == Just(Plus(x, Mult(x, Ident(\"y\")))))\n",
    "passed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Negation\n",
    "val x = Ident(\"x\")\n",
    "assert(runExprParser(parseE, \"- x \") == Just(Neg(x)))\n",
    "assert(runExprParser(parseE, \"- - - x \") == Just(Neg(Neg(Neg(x)))))\n",
    "assert(runExprParser(parseE, \"- x * - x \") == Just(Mult(Neg(x), Neg(x))))\n",
    "passed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Function Calls\n",
    "val f = Ident(\"f\")\n",
    "val x = Ident(\"x\")\n",
    "assert(runExprParser(parseE, \"f ( x ) \") == Just(FunCall(f, x)))\n",
    "assert(runExprParser(parseE, \"f ( x ) ( x ) \") == Just(FunCall(FunCall(f, x), x)))\n",
    "assert(runExprParser(parseE, \"- f ( x ) \") == Just(Neg(FunCall(f, x))))\n",
    "passed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Parens\n",
    "val x = Ident(\"x\")\n",
    "assert(runExprParser(parseE, \"( x ) \") == Just(x))\n",
    "assert(runExprParser(parseE, \"( ( x ) ) \") == Just(x))\n",
    "assert(runExprParser(parseE, \"( x + x ) * x \") == Just(Mult(Plus(x, x), x)))\n",
    "passed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "// If\n",
    "val x = Ident(\"x\")\n",
    "val y = Ident(\"y\")\n",
    "assert(runExprParser(parseE, \"if x then x else x \") == Just(IfThenElse(x, x, x)))\n",
    "assert(runExprParser(parseE, \"y + if x then y else ( x + y ) \") == Just(Plus(y, IfThenElse(x, y, Plus(x, y)))))\n",
    "assert(runExprParser(parseE, \"if if x then x else x then if x then x else x else if x then x else x \")\n",
    "       == Just(IfThenElse(IfThenElse(x, x, x), IfThenElse(x, x, x), IfThenElse(x, x, x))))\n",
    "passed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Functions\n",
    "val x = Ident(\"x\")\n",
    "val y = Ident(\"y\")\n",
    "assert(runExprParser(parseE, \"function ( x ) x \") == Just(FunDef(\"x\", x)))\n",
    "assert(runExprParser(parseE, \"( function ( x ) x ) ( y ) \") == Just(FunCall(FunDef(\"x\", x), y)))\n",
    "assert(runExprParser(parseE, \"function ( x + x ) x \") == None)\n",
    "passed(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}